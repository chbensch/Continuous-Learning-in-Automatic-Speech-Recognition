{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import kenlm\n",
    "import ctcdecode\n",
    "import pickle\n",
    "import numpy as np\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, Wav2Vec2CTCTokenizer, Wav2Vec2FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\", unk_token=\"[UNK]\", pad_token=\"[PAD]\", word_delimiter_token=\"|\")\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=True)\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\"./wav2vec2-large-xlsr-ger-chris/checkpoint-51000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = tokenizer.get_vocab()\n",
    "sort_vocab = sorted((value, key) for (key,value) in vocab_dict.items())\n",
    "vocab = [x[1].replace(\"|\", \" \") if x[1] not in tokenizer.all_special_tokens else \"_\" for x in sort_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1gram\n",
      "found 2gram\n"
     ]
    }
   ],
   "source": [
    "alpha = 2.5 # LM Weight\n",
    "beta = 0.0 # LM Usage Reward\n",
    "word_lm_scorer = ctcdecode.WordKenLMScorer('lm_data/train.arpa', alpha, beta) # use your own kenlm model\n",
    "\n",
    "decoder = ctcdecode.BeamSearchDecoder(\n",
    "    vocab,\n",
    "    num_workers=16,\n",
    "    beam_width=128,\n",
    "    scorers=[word_lm_scorer],\n",
    "    cutoff_prob=np.log(0.000001),\n",
    "    cutoff_top_n=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_result(batch):\n",
    "    \n",
    "    model.to(\"cuda\")\n",
    "    input_values = processor(\n",
    "          batch[\"speech\"], \n",
    "          sampling_rate=batch[\"sampling_rate\"], \n",
    "          return_tensors=\"pt\"\n",
    "    ).input_values.to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_values).logits\n",
    "\n",
    "    pred_ids = torch.argmax(logits, dim=-1)\n",
    "    batch[\"pred_str\"] = processor.batch_decode(pred_ids)[0]\n",
    "    \n",
    "    batch[\"lm_raw\"] = logits[0].cpu().numpy()\n",
    "    \n",
    "    #batch[\"lm_str\"] = decode(logits[0].cpu().numpy())\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "test_sampled = load_from_disk(\"E:/Master/data/test_sampled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15588, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef9635575ba144509fdadb75b3e5cd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15588.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results51_full = test_sampled.map(map_to_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "results51_full.save_to_disk(\"res51_full_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "results51 = load_from_disk(\"res51_full_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_lm(batch, word_lm_scorer, vocabulary):\n",
    "    from ctcdecode.prefix import State\n",
    "    import numpy as np\n",
    "\n",
    "    def get_pruned_vocab_indices(log_probs):\n",
    "        \"\"\" Return vocab indices of pruned probabilities of a time step. \"\"\"\n",
    "\n",
    "        index_to_prob = [(k, log_probs[k]) for k in range(log_probs.shape[0])]\n",
    "        index_to_prob = sorted(index_to_prob, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        if 40 < len(index_to_prob):\n",
    "            index_to_prob = index_to_prob[:40]\n",
    "\n",
    "        if np.log(0.000001) < 1.0:\n",
    "            filtered = []\n",
    "            for x in index_to_prob:\n",
    "                if x[1] >= np.log(0.000001):\n",
    "                    filtered.append(x)\n",
    "            index_to_prob = filtered\n",
    "\n",
    "        return [x[0] for x in index_to_prob]\n",
    "\n",
    "    def decode(probs):\n",
    "        # Num time steps\n",
    "        nT = probs.shape[0]\n",
    "\n",
    "        # Initialize prefixes\n",
    "        prefixes = State(\n",
    "            scorers=[word_lm_scorer],\n",
    "            size=128\n",
    "        )\n",
    "\n",
    "        # Iterate over timesteps\n",
    "        for t in range(nT):\n",
    "            step_probs = probs[t]\n",
    "            pruned_step_probs = get_pruned_vocab_indices(step_probs)\n",
    "\n",
    "            # Iterate over symbols\n",
    "            for v in pruned_step_probs:\n",
    "                symbol = vocabulary[v]\n",
    "                symbol_prob = step_probs[v]\n",
    "\n",
    "                # Iterate over prefixes\n",
    "                for prefix in prefixes:\n",
    "\n",
    "                    # If there is a blank, we extend the existing prefix\n",
    "                    if symbol == '_':\n",
    "                        prefix.add_p_blank(symbol_prob + prefix.score)\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        # If the last symbol is repeated\n",
    "                        # update the existing prefix\n",
    "                        if symbol == prefix.symbol:\n",
    "                            p = symbol_prob + prefix.p_non_blank_prev\n",
    "                            prefix.add_p_non_blank(p)\n",
    "\n",
    "                        new_prefix = prefixes.get_prefix(prefix, symbol)\n",
    "\n",
    "                        if new_prefix is not None:\n",
    "                            p = -np.inf\n",
    "\n",
    "                            if symbol == prefix.symbol and \\\n",
    "                                    prefix.p_blank_prev > -np.inf:\n",
    "                                p = prefix.p_blank_prev + symbol_prob\n",
    "\n",
    "                            elif prefix.symbol != symbol:\n",
    "                                p = prefix.score + symbol_prob\n",
    "\n",
    "                            new_prefix.add_p_non_blank(p)\n",
    "\n",
    "            prefixes.step()\n",
    "\n",
    "        prefixes.finalize()\n",
    "\n",
    "        return prefixes.best()\n",
    "\n",
    "    batch[\"lm_str\"] = decode(np.asarray(batch[\"lm_raw\"]))\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results51_lm = results51.map(infer_lm, fn_kwargs=dict(word_lm_scorer=word_lm_scorer, vocabulary=vocabulary), num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_str = decode(lm_str_raw[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zieht euch bitte draußen die schuhe aus \n"
     ]
    }
   ],
   "source": [
    "print(lm_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk, load_dataset\n",
    "\n",
    "results51_full = load_from_disk(\"results51_test\")\n",
    "results51_cut = load_from_disk(\"results51_cut\")\n",
    "results51_cut_log = load_from_disk(\"res51_cut_log\")\n",
    "results51_full_log = load_from_disk(\"res51_full_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test WER: 0.175\n"
     ]
    }
   ],
   "source": [
    "print(\"Test WER: {:.3f}\".format(wer_metric.compute(predictions=results51[\"lm_str\"], references=results51[\"target_text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import ClassLabel\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lm_str</th>\n",
       "      <th>pred_str</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>insgesamt ist der sound etwas zu basslastige</td>\n",
       "      <td>insgesamt ist der sound etwas zu basslastig</td>\n",
       "      <td>insgesamt ist der sound etwas zu basslastig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weshalb möchtest du nach bergheim</td>\n",
       "      <td>weshalb möchtest du nach bergheim</td>\n",
       "      <td>weshalb möchtest du nach bergheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wir müssen zwei dinge ganz klar unterscheiden</td>\n",
       "      <td>wir müssen zwei dinge ganz klar unterscheiden</td>\n",
       "      <td>wir müssen zwei dinge ganz klar unterscheiden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>auflage des wettbewerbs</td>\n",
       "      <td>aufflage des wettbewerbes</td>\n",
       "      <td>auflage des wettbewerbes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>felipe hat eine auch für monarchen ungewöhnlich lange titelliste</td>\n",
       "      <td>velipe hat eine auch für monarchen ungewöhnlich lange titelliste</td>\n",
       "      <td>felipe hat eine auch für monarchen ungewöhnlich lange titelliste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seinen vornamen erhielt er in gedenken an seinem früh verstorbenen onkel</td>\n",
       "      <td>seinen vornamen erhielt er in gedenken an seinem früh verstorbenen onkel</td>\n",
       "      <td>seinen vornamen erhielt er in gedenken an seinen früh verstorbenen onkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>was solls ich bin bereit</td>\n",
       "      <td>was solls ich bin bereit</td>\n",
       "      <td>was solls ich bin bereit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>er wurde zu ehren des reichskanzler otto von bismarck errichtet</td>\n",
       "      <td>er wurde zu ehren des reichskanzlers otto von bismark errichtet</td>\n",
       "      <td>er wurde zu ehren des reichskanzlers otto von bismarck errichtet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sie war die cousine von karl maria von weber</td>\n",
       "      <td>sie war die cousine von karlmaria von weber</td>\n",
       "      <td>sie war die cousine von carl maria von weber</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>der uranus ist der siebente planet in unserem sonnensystem</td>\n",
       "      <td>der uranus ist der siebentelplanet in unserem sonnensystem</td>\n",
       "      <td>der uranus ist der siebente planet in unserem sonnensystem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(results51.remove_columns([\"speech\", \"sampling_rate\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
